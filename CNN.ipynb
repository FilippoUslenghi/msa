{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z0mIezofgJgk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tORwxj72lLGt",
    "outputId": "9e6c2295-6c6a-43dd-bc7a-043a397505ad",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in the dataset: 24951\n"
     ]
    }
   ],
   "source": [
    "# Define the directory of the dataset\n",
    "data_dir = pathlib.Path('/Users/filippouslenghi/msa/dataset')\n",
    "# Collects the path of all the files within the dataset\n",
    "data_paths = [str(path) for path in list(data_dir.glob(\"*/*.jpg\"))]\n",
    "print(f\"Images in the dataset: {len(data_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5LT9AmAR0HM4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the training and test sets using the paths of the images\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_paths, test_paths = train_test_split(data_paths, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "orirMLaP754O",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 19:46:49.081918: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-04 19:46:49.082099: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Create the respective tf.data.Dataset objects\n",
    "train = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "test = tf.data.Dataset.from_tensor_slices(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tD0OCF6x-5q6",
    "outputId": "02925486-5db8-4b36-8835-c9ef6d662a18",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cats' 'Dogs']\n"
     ]
    }
   ],
   "source": [
    "# Get the class names\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5cJWtxfo_K-U",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a validation set\n",
    "val_size = int(len(list(train)) * 0.2)\n",
    "train = train.skip(val_size)\n",
    "val = train.take(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VXF62vBlJj9e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set initial params for the loader\n",
    "batch_size = 64\n",
    "img_height = 200\n",
    "img_width = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "arSQzIey-4D4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    # Convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    one_hot = parts[-2] == class_names\n",
    "    # Integer encode the label\n",
    "    return tf.argmax(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MGlq4IP4Aktb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    # Convert the compressed string to a 3D uint8 tensor\n",
    "    try:\n",
    "        img = tf.io.decode_jpeg(img, channels=3)\n",
    "    except:\n",
    "        img = tf.io.decode_bmp(img, channels=3)\n",
    "    # Resize the image to the desired size\n",
    "    return tf.image.resize(img, [img_height, img_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-xhBRgvNqRRe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # Load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "XsGQx56YHoe9",
    "outputId": "04769f91-bfeb-4257-c253-9b9653224a78",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataset of image, label pairs\n",
    "train = train.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val = val.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test = test.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "S3uDN1TiKOFR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Configure dataset for performance\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train = configure_for_performance(train)\n",
    "val = configure_for_performance(val)\n",
    "test = configure_for_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "En29RHVsKWIW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KM1r5OcXhBhE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "YdZe2-WENlAe",
    "outputId": "7b72d900-279d-4c4e-de8f-d7f5e765a56a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 26s 102ms/step - loss: 0.4237 - accuracy: 0.8038 - val_loss: 0.3946 - val_accuracy: 0.8186\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.3772 - accuracy: 0.8271 - val_loss: 0.3390 - val_accuracy: 0.8540\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 25s 98ms/step - loss: 0.3312 - accuracy: 0.8546 - val_loss: 0.3456 - val_accuracy: 0.8467\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.2714 - accuracy: 0.8856 - val_loss: 0.2521 - val_accuracy: 0.8935\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.2226 - accuracy: 0.9074 - val_loss: 0.2526 - val_accuracy: 0.8930\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 26s 101ms/step - loss: 0.1723 - accuracy: 0.9294 - val_loss: 0.1622 - val_accuracy: 0.9341\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 25s 98ms/step - loss: 0.1312 - accuracy: 0.9502 - val_loss: 0.1536 - val_accuracy: 0.9366\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 26s 101ms/step - loss: 0.0914 - accuracy: 0.9666 - val_loss: 0.1130 - val_accuracy: 0.9512\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0715 - accuracy: 0.9744 - val_loss: 0.1423 - val_accuracy: 0.9456\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 0.0521 - accuracy: 0.9818 - val_loss: 0.0807 - val_accuracy: 0.9694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3649d6f10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train,\n",
    "    validation_data=val,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "my_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4c80273f820a83c379f64d194ef315a659c6480fd4fab5c2029c9be193cfc0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
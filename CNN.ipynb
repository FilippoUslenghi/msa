{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%pip install -q gdown"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2274,"status":"ok","timestamp":1657211830263,"user":{"displayName":"Filippo Uslenghi","userId":"02060675236977838476"},"user_tz":-120},"id":"-LryX5xFgg7u","outputId":"238fb8f8-b99c-4f8c-c043-d167372a9a03","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["import os\n","import gdown\n","\n","url = \"https://drive.google.com/uc?id=1-TEMm7jaSYVlSaEqciFQleeAB_rCKoiY\"\n","name = \"CatsDogs.zip\"\n","\n","gdown.download(url, name, quiet=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["os.system('unzip -oq CatsDogs.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11469,"status":"ok","timestamp":1657212338604,"user":{"displayName":"Filippo Uslenghi","userId":"02060675236977838476"},"user_tz":-120},"id":"Z0mIezofgJgk","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["import os\n","import pathlib\n","import numpy as np\n","from PIL import Image\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":634,"status":"ok","timestamp":1657211842788,"user":{"displayName":"Filippo Uslenghi","userId":"02060675236977838476"},"user_tz":-120},"id":"tORwxj72lLGt","outputId":"e18916b4-e12a-4b9d-d567-e2469d1a3b82","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# Define the directory of the dataset\n","data_dir = pathlib.Path('CatsDogs/')\n","\n","# Remove corrupted files\n","os.system(\"rm CatsDogs/Cats/666.jpg CatsDogs/Dogs/11702.jpg CatsDogs/Dogs/11410.jpg\")\n","\n","# Collects the path of all the files within the dataset\n","data_paths = [str(path) for path in list(data_dir.glob(\"*/*.jpg\"))]\n","print(f\"Images in the dataset: {len(data_paths)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Convert non-jpeg images into jpeg files\n","formats = [(path, Image.open(path).format) for path in data_paths]\n","non_jpegs = list(filter(lambda x: x[1]!='JPEG', formats))\n","for path, _ in non_jpegs:\n","    img = Image.open(path)\n","    img.convert('RGB').save(path, format='JPEG')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"orirMLaP754O","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# Create the respective tf.data.Dataset object\n","dataset = tf.data.Dataset.from_tensor_slices(data_paths)\n","# Shuffle the dataset\n","dataset = dataset.shuffle(len(data_paths), reshuffle_each_iteration=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1657211850149,"user":{"displayName":"Filippo Uslenghi","userId":"02060675236977838476"},"user_tz":-120},"id":"UImc8RD4Ejlh","outputId":"07af990f-15e4-40a9-e5ac-a0f77611f792","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# Get the class names\n","class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name[0] != '.']))\n","print(class_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5cJWtxfo_K-U","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# Spilt the dataset\n","test_size = int(len(list(dataset)) * 0.2)\n","train = dataset.skip(test_size)\n","test = dataset.take(test_size)\n","\n","# Create a validation set\n","val_size = int(len(list(train))*0.2)\n","val = train.take(val_size)\n","train = train.skip(val_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VXF62vBlJj9e","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# Set initial params for the loader\n","batch_size = 64\n","img_height = 150\n","img_width = 150"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"arSQzIey-4D4","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["def get_label(file_path):\n","    # Convert the path to a list of path components\n","    parts = tf.strings.split(file_path, os.path.sep)\n","    # The second to last is the class-directory\n","    one_hot = parts[-2] == class_names\n","    # Integer encode the label\n","    return tf.argmax(one_hot)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MGlq4IP4Aktb","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["def decode_img(img):\n","    # Convert the compressed string to a 3D uint8 tensor\n","    img = tf.io.decode_jpeg(img, channels=3)\n","    # Resize the image to the desired size\n","    return tf.image.resize(img, [img_height, img_width])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-xhBRgvNqRRe","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["def process_path(file_path):\n","    label = get_label(file_path)\n","    # Load the raw data from the file as a string\n","    img = tf.io.read_file(file_path)\n","    img = decode_img(img)\n","    return img, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XsGQx56YHoe9","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# Create a dataset of image, label pairs\n","train = train.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n","test = test.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n","val = val.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Configure dataset for performance\n","def configure_for_performance(ds):\n","    ds = ds.cache()\n","    ds = ds.shuffle(buffer_size=1000)\n","    ds = ds.batch(batch_size)\n","    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n","    return ds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S3uDN1TiKOFR","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["train = configure_for_performance(train)\n","test = configure_for_performance(test)\n","val = configure_for_performance(val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"En29RHVsKWIW","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Rescaling(1./255),\n","    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPooling2D(),\n","    # tf.keras.layers.Dropout(0.25),\n","    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n","    tf.keras.layers.MaxPooling2D(),\n","    # tf.keras.layers.Dropout(0.25),\n","    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n","    tf.keras.layers.MaxPooling2D(),\n","    tf.keras.layers.Flatten(),\n","    # tf.keras.layers.Dropout(0.25),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    # tf.keras.layers.Dropout(0.25),\n","    # tf.keras.layers.Dense(128, activation='leaky_relu'),\n","    # tf.keras.layers.Dropout(0.25),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KM1r5OcXhBhE","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["model.compile(\n","    optimizer='adam',\n","    loss='binary_crossentropy',\n","    metrics=['accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":181377,"status":"ok","timestamp":1657212039899,"user":{"displayName":"Filippo Uslenghi","userId":"02060675236977838476"},"user_tz":-120},"id":"YdZe2-WENlAe","outputId":"fdad4070-2f5c-4c50-e247-009b8801483a","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["n_epochs = 20\n","model.fit(\n","    train,\n","    epochs=n_epochs,\n","    validation_data=val\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["def zero_one_loss(dataset, dataset_size):\n","    \n","    _, accuracy = model.evaluate(dataset)\n","    zero_one_loss = dataset_size*(1-accuracy)\n","\n","    return int(round(zero_one_loss, ndigits=0))"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["print(f\"Zero-one loss on the test set: {zero_one_loss(test, test_size)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Clear any previous state\n","del train, test, model, dataset, test_size, formats, non_jpegs\n","tf.keras.backend.clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import gc\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["# K-fold cross validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"69XJrMJsiR03","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["\"\"\"\n","from sklearn.model_selection import KFold\n","\n","\n","k_fold = KFold(n_splits=5, shuffle=True)\n","k_splits = k_fold.split(data_paths)\n","results = []\n","\n","for train_index, test_index in k_splits:\n","\n","    # Get the paths to the data\n","    train_paths = np.asarray(data_paths)[train_index]\n","    test_paths = np.asarray(data_paths)[test_index]\n","\n","    # Make it tf.data.Dataset\n","    train = tf.data.Dataset.from_tensor_slices(train_paths)\n","    test = tf.data.Dataset.from_tensor_slices(test_paths)\n","\n","    # Shuffle the dataset\n","    train = train.shuffle(len(train))\n","    test = test.shuffle(len(test))\n","\n","    # Get labels\n","    train = train.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n","    test = test.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n","    \n","    # Configure for performance\n","    train = configure_for_performance(train)\n","    test = configure_for_performance(test)\n","\n","    # Create the model\n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Rescaling(1./255),\n","        tf.keras.layers.Conv2D(16, 3, activation='relu', input_shape=(150, 150, 3)),\n","        tf.keras.layers.MaxPooling2D(),\n","        tf.keras.layers.Dropout(0.1),\n","        tf.keras.layers.Conv2D(32, 3, activation='relu'),\n","        tf.keras.layers.MaxPooling2D(),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Conv2D(64, 3, activation='relu'),\n","        tf.keras.layers.MaxPooling2D(),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dropout(0.3),\n","        tf.keras.layers.Dense(128, activation='relu'),\n","        tf.keras.layers.Dropout(0.4),\n","        tf.keras.layers.Dense(1, activation='sigmoid')\n","    ])\n","\n","    model.compile(\n","        optimizer='adam',\n","        loss='binary_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    model.fit(\n","        train,\n","        epochs=n_epochs,\n","        verbose=0,\n","    )\n","\n","    loss = zero_one_loss(test, len(test_paths))\n","    results.append(loss)\n","    print(f\"Zero-one loss: {loss}\")\n","\n","    # Clear any previous state\n","    del model\n","    tf.keras.backend.clear_session()\n","    gc.collect()\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5LsUvuXDG9g","pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["\"\"\" \n","mean_loss = np.round(np.mean(results), decimals=0)\n","std_loss = np.round(np.std(results), decimals=0)\n","print(f'The mean of zero-one loss is {int(mean_loss)}, with a standard deviation of {int(std_loss)} missmatched samples')\n","\"\"\""]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('visart')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"0bb77c6cb71ba4a7f7f0e8e08f8700abef1980870bd72f32fe1d9c2ef1e40dce"}}},"nbformat":4,"nbformat_minor":4}
